{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "import sys\n",
    "import numpy as np\n",
    "import scipy.misc\n",
    "import os\n",
    "import tensorflow as tf\n",
    "import ops"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "from glob import glob\n",
    "data = glob(os.path.join(\"/home/zhangjinbin/research/data/\", \"*.jpg\"))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "slim = tf.contrib.slim"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "def _conv_layer(net,filter_size,strides,num_filters, scope,x_att=None):\n",
    "    with tf.variable_scope(scope):\n",
    "        if x_att==None:\n",
    "            weights_init = _conv_init_vars(net, num_filters, filter_size,scope)\n",
    "            strides_shape = [1, strides, strides, 1]\n",
    "            padding = filter_size // 2\n",
    "            padded_input = tf.pad(\n",
    "                net, [[0, 0], [padding, padding], [padding, padding], [0, 0]],mode='REFLECT')\n",
    "            net = tf.nn.conv2d(padded_input, weights_init, strides_shape, padding='VALID')\n",
    "            return net\n",
    "        else:\n",
    "            weights_init = _conv_init_vars(net, num_filters, filter_size,scope)\n",
    "            #[filter_size, filter_size, in_channels, out_channels]\n",
    "            filter_size, filter_size, in_channels, out_channels = [i.value for i in weights_init.get_shape()]\n",
    "            hidden  = tf.nn.relu(linear(x_att,  1000, scope='c_h1', stddev=0.01))\n",
    "            control_net = tf.nn.sigmoid(linear(hidden,filter_size*filter_size*in_channels*out_channels,scope='c_wc',stddev=0.01))\n",
    "            control_net= tf.reshape(control_net,[-1,filter_size, filter_size, in_channels, out_channels])\n",
    "            weights_initnew=[]\n",
    "            for i in range(batch_size):\n",
    "                weights_initi = tf.mul(control_net[i,:,:,:],weights_init)\n",
    "                weights_initnew.append(weights_initi)\n",
    "            #scale_c = tf.nn.sigmoid(linear(hidden,  rows*cols*channels, scope='c_sc', stddev=0.01))\n",
    "            strides_shape = [1, strides, strides, 1]\n",
    "            padding = filter_size // 2\n",
    "            padded_input = tf.pad(\n",
    "                net, [[0, 0], [padding, padding], [padding, padding], [0, 0]],mode='REFLECT')\n",
    "            conv_out= []\n",
    "            for i in range(batch_size):\n",
    "                conv_out.append(tf.nn.conv2d([padded_input[i,:,:,:]], weights_initnew[i], strides_shape, padding='VALID'))   \n",
    "            #net = _instance_norm(net)\n",
    "            net = tf.concat(0,conv_out)\n",
    "            return net\n",
    "def _conv_init_vars(net, out_channels, filter_size,scope, transpose=False,stddev =0.01):\n",
    "    _, rows, cols, in_channels = [i.value for i in net.get_shape()]\n",
    "    if not transpose:\n",
    "        weights_shape = [filter_size, filter_size, in_channels, out_channels]\n",
    "    else:\n",
    "        weights_shape = [filter_size, filter_size, out_channels, in_channels]\n",
    "    norm = tf.random_normal_initializer(stddev=stddev)\n",
    "    with tf.variable_scope(scope):\n",
    "        weights_init = tf.get_variable('weight',weights_shape, initializer=norm)\n",
    "    return weights_init\n",
    "def _residual_block(input_, kernel_size, scope,x_att=None):\n",
    "    with tf.variable_scope(scope):\n",
    "        num_outputs = input_.get_shape()[-1].value\n",
    "        h_1 = _conv_layer(input_, kernel_size, 1, num_outputs, 'conv1',x_att=x_att)\n",
    "        h_2 = _conv_layer(h_1, kernel_size, 1, num_outputs, 'conv2',x_att=x_att)\n",
    "        return input_ + h_2\n",
    "def _upsampling(input_, kernel_size, stride, num_outputs, scope):\n",
    "    if kernel_size % 2 == 0:\n",
    "        raise ValueError('kernel_size is expected to be odd.')\n",
    "    with tf.variable_scope(scope):\n",
    "        _, height, width, _ = [s.value for s in input_.get_shape()]\n",
    "        upsampled_input = tf.image.resize_nearest_neighbor(\n",
    "        input_, [stride * height, stride * width])\n",
    "        return _conv_layer(upsampled_input, kernel_size, 1, num_outputs, 'conv')\n",
    "\n",
    "def _instance_norm(net,x_att,batch_size,scope,train=True):\n",
    "    batch, rows, cols, channels = [i.value for i in net.get_shape()]\n",
    "    var_shape = [channels]\n",
    "    mu, sigma_sq = tf.nn.moments(net, [1,2], keep_dims=True)\n",
    "    shift = tf.Variable(tf.zeros(var_shape))\n",
    "    scale = tf.Variable(tf.ones(var_shape))\n",
    "    epsilon = 1e-3\n",
    "    normalized = (net-mu)/(sigma_sq + epsilon)**(.5)\n",
    "    return scale * normalized + shift\n",
    "def shift_scale_get(x_att,net,scope):\n",
    "    norm = tf.random_normal_initializer(stddev=0.001)\n",
    "    const = tf.constant_initializer(1.0)\n",
    "    batch, rows, cols, channels = [i.value for i in net.get_shape()]\n",
    "    with tf.variable_scope(scope):\n",
    "        hidden  = tf.nn.relu(linear(x_att,  1000, scope='c_h1', stddev=0.01))\n",
    "        shift_c = tf.nn.sigmoid(linear(hidden,  rows*cols*channels, scope='c_sh', stddev=0.01))\n",
    "        scale_c = tf.nn.sigmoid(linear(hidden,  rows*cols*channels, scope='c_sc', stddev=0.01))\n",
    "        shift = tf.get_variable('shift', [batch_size,channels], initializer=norm)\n",
    "        scale = tf.get_variable('scalse', [batch_size,channels], initializer=const)\n",
    "        shift_ = tf.reshape(shift_c,[-1,rows, cols, channels])#tf.mul(shift,shift_c)+tf.mul(shift,tf.sub(tf.ones_like(shift_c),shift_c))\n",
    "        scale_ = tf.reshape(scale_c,[-1,rows, cols, channels])#tf.mul(scale,scale_c)+tf.mul(scale,tf.sub(tf.ones_like(scale_c),scale_c))\n",
    "        print('mormshift:')\n",
    "        print(shift_.get_shape())\n",
    "    return shift_,scale_\n",
    "def linear(input, output_dim, scope=None, stddev=0.01):\n",
    "    norm = tf.random_normal_initializer(stddev=stddev)\n",
    "    const = tf.constant_initializer(0.0)\n",
    "    with tf.variable_scope(scope or 'linear'):\n",
    "        w = tf.get_variable('w', [input.get_shape()[1], output_dim], initializer=norm)\n",
    "        b = tf.get_variable('b', [output_dim], initializer=const)\n",
    "        return tf.matmul(input, w) + b"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def recognition_network(images,reuse = False):\n",
    "    if reuse:\n",
    "        tf.get_variable_scope().reuse_variables()\n",
    "    with tf.variable_scope('r_recognition', reuse=reuse):\n",
    "        with tf.variable_scope('r_dis'):\n",
    "            h = _conv_layer(images, 9, 2, 32, 'r_conv1')\n",
    "            h = tf.nn.relu(h)\n",
    "            h = _conv_layer(h, 3, 2, 64, 'r_conv2')\n",
    "            h = tf.nn.relu(h)\n",
    "            h = _conv_layer(h, 3, 2, 128, 'r_conv3')\n",
    "            h = tf.nn.relu(h)\n",
    "            h = _conv_layer(h, 3, 2, 256, 'r_conv4')\n",
    "            h = tf.nn.relu(h)\n",
    "            h = _conv_layer(h, 3, 2, 512, 'r_conv5')\n",
    "            h = tf.nn.relu(h)\n",
    "            h = _conv_layer(h, 3, 2, 1024, 'r_conv6')\n",
    "            h = tf.reshape(h,[-1,1024])\n",
    "            h = tf.nn.relu(h)\n",
    "            print(h.get_shape())\n",
    "            output = tf.nn.relu(linear(h, 1000, scope='r_layer1', stddev=0.01))\n",
    "            output = tf.nn.softmax(linear(output, 2, scope='r_layer2', stddev=0.01))\n",
    "            return output"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "def transform(input_,x_att,batch_size,reuse=False):\n",
    "    with tf.variable_scope('c_transformer', reuse=reuse):\n",
    "        with tf.variable_scope('c_contract'):\n",
    "            h = _conv_layer(input_, 9, 1, 32, 'c_conv1',x_att=x_att )\n",
    "            h = _instance_norm(h,x_att,batch_size,'c_norm1',train=True)\n",
    "            h = tf.nn.relu(h)\n",
    "            print(h.get_shape())\n",
    "            h = _conv_layer(h, 3, 2, 64, 'c_conv2',x_att=x_att)\n",
    "            h = _instance_norm(h,x_att,batch_size,'c_norm2',train=True)\n",
    "            h = tf.nn.relu(h)\n",
    "            print(h.get_shape())\n",
    "            h = _conv_layer(h, 3, 2, 128, 'c_conv3',x_att=x_att)\n",
    "            h = _instance_norm(h,x_att,batch_size,'c_norm3',train=True)\n",
    "            h = tf.nn.relu(h)\n",
    "            print(h.get_shape())\n",
    "        with tf.variable_scope('c_residual'):\n",
    "            h = _residual_block(h, 3, 'c_residual1',x_att=x_att)\n",
    "            h = _instance_norm(h,x_att,batch_size,'c_norm4',train=True)\n",
    "            h = tf.nn.relu(h)\n",
    "            print(h.get_shape())\n",
    "            h = _residual_block(h, 3, 'c_residual2',x_att=x_att)\n",
    "            h = _instance_norm(h,x_att,batch_size,'c_norm5',train=True)\n",
    "            h = tf.nn.relu(h)\n",
    "            print(h.get_shape())\n",
    "            h = _residual_block(h, 3, 'c_residual3',x_att=x_att)\n",
    "            h = _instance_norm(h,x_att,batch_size,'c_norm6',train=True)\n",
    "            h = tf.nn.relu(h)\n",
    "            print(h.get_shape())\n",
    "            h = _residual_block(h, 3, 'c_residual4',x_att=x_att)\n",
    "            h = _instance_norm(h,x_att,batch_size,'c_norm7',train=True)\n",
    "            h = tf.nn.relu(h)\n",
    "            print(h.get_shape())\n",
    "            h = _residual_block(h, 3, 'c_residual5',x_att=x_att)\n",
    "            h = _instance_norm(h,x_att,batch_size,'c_norm8',train=True)\n",
    "            h = tf.nn.relu(h)\n",
    "            print(h.get_shape())\n",
    "        with tf.variable_scope('c_expand'):\n",
    "            h = _upsampling(h, 3, 2, 64, 'c_conv1_')\n",
    "            h = _instance_norm(h,x_att,batch_size,'c_norm9',train=True)\n",
    "            h = tf.nn.relu(h)\n",
    "            print(h.get_shape())\n",
    "            h = _upsampling(h, 3, 2, 32, 'c_conv2_')\n",
    "            h = _instance_norm(h,x_att,batch_size,'c_norm10',train=True)\n",
    "            h = tf.nn.relu(h)\n",
    "            print(h.get_shape())\n",
    "            return _upsampling(h, 9, 1, 3, 'c_conv3_')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false,
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "batch_size = 32\n",
    "# weights_shape=[4,4,3,12]\n",
    "# weights_init = tf.Variable(tf.truncated_normal(weights_shape, stddev=0.01), dtype=tf.float32)\n",
    "input_img = tf.placeholder(tf.float32, shape=[batch_size,64,64,3], name=\"input_img\")\n",
    "x_attr = tf.placeholder(tf.float32, [batch_size, 2], name=\"input_attri\")\n",
    "\n",
    "\n",
    "out_img = transform(input_img/255.0,x_attr,batch_size)\n",
    "reconstruction_loss = tf.reduce_mean(tf.squared_difference(out_img,input_img/255.0))\n",
    "pre_att_input = recognition_network(input_img/255.0)\n",
    "y_pre =  tf.argmax(pre_att_input, 1, name=\"predictions\")\n",
    "x_attr_ = tf.argmax(x_attr, 1, name=\"true_predictions\")\n",
    "correct_predictions = tf.equal(x_attr_, y_pre)\n",
    "accuracy = tf.reduce_mean(tf.cast(correct_predictions, \"float\"), name=\"accuracy\")\n",
    "\n",
    "pre_att_gen = recognition_network(out_img,reuse =True)\n",
    "recog_attr_loss = tf.reduce_mean(tf.nn.softmax_cross_entropy_with_logits(pre_att_input,x_attr))\n",
    "gen_attr_loss = tf.reduce_mean(tf.nn.softmax_cross_entropy_with_logits(pre_att_gen,x_attr))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "loss = reconstruction_loss + 10*gen_attr_loss\n",
    "t_vars = tf.trainable_variables()\n",
    "contr_params = [var for var in t_vars if 'c_' in var.name]\n",
    "recog_params = [var for var in t_vars if 'r_' in var.name]\n",
    "\n",
    "optim = tf.train.AdamOptimizer(learning_rate=1e-3). \\\n",
    "        minimize(loss,var_list=contr_params) \n",
    "optim_re_attr= tf.train.AdamOptimizer(learning_rate=1e-3). \\\n",
    "        minimize(recog_attr_loss,var_list=recog_params) \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def get_imgs(path_batch):\n",
    "    batch_img = []\n",
    "    for path in path_batch:\n",
    "        img = scipy.misc.imread(path, mode='RGB')\n",
    "        batch_img.append(img)\n",
    "    return batch_img"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "def onetozero(x):\n",
    "    if x ==-1:\n",
    "        return 0\n",
    "    else:\n",
    "        return x\n",
    "attributes ={}\n",
    "#[4,5,8,9,15,20,26,31]\n",
    "att_all = []\n",
    "with open('list_attr_celeba.txt', 'r') as f:\n",
    "    f.readline()\n",
    "    attribute_names = f.readline().strip().split(' ')\n",
    "    for i, line in enumerate(f):\n",
    "        fields = line.strip().replace('  ', ' ').split(' ')\n",
    "        img_name = fields[0]\n",
    "        if int(img_name[:6]) != i + 1:\n",
    "            raise ValueError('Parse error.')\n",
    "        attr_vec = map(int, fields[1:])\n",
    "        att = attr_vec[15]\n",
    "        if att ==-1:\n",
    "            att =  0\n",
    "        att_hot = [0,0]\n",
    "        att_hot[att]=1\n",
    "        attributes[img_name]= att_hot\n",
    "        att_all.append(att_hot)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false,
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "os.environ.setdefault('CUDA_VISIBLE_DEVICES','1')\n",
    "session_conf = tf.ConfigProto(gpu_options = tf.GPUOptions(per_process_gpu_memory_fraction=0.7),\n",
    "                              allow_soft_placement=True,\n",
    "                              log_device_placement=False)\n",
    "sess = tf.InteractiveSession(config=session_conf)\n",
    "# Train\n",
    "tf.initialize_all_variables().run()\n",
    "step =0\n",
    "# data_batch = data[step*batch_size:(step+1)*batch_size]\n",
    "# x_batch = get_imgs(data_batch)\n",
    "# attr_batch = [attributes[element[-10:]] for element in data_batch]\n",
    "# ot1,loss, recon_image,_ = sess.run([re_att,reconstruction_loss,out_img,optim_recog],\n",
    "#                                feed_dict={input_img:x_batch ,x_attr:attr_batch})\n",
    "#for epoch in range(epoches):\n",
    "for step in range(2001):\n",
    "    data_batch = data[step*batch_size:(step+1)*batch_size]\n",
    "    x_batch = get_imgs(data_batch)\n",
    "    attr_batch = [attributes[element[-10:]] for element in data_batch]\n",
    "    acc,loss_,reloss,recon_image,_,_= sess.run([accuracy,loss,reconstruction_loss,out_img,optim_re_attr,optim],\n",
    "                                   feed_dict={input_img:x_batch ,x_attr:attr_batch})\n",
    "    \n",
    "    if step %100 ==0:\n",
    "        scipy.misc.imsave('./sample/%s_input.png'% (step),x_batch[0])\n",
    "        scipy.misc.imsave('./sample/%s_output.png'% (step),recon_image[0]) \n",
    "    if step%20 ==0:\n",
    "        print('step :'+str(step)+' loss :'+str(loss_)+' re_loss :'+str(reloss)+' acc :'+str(acc))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "att_all[-8:]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "#batch_xs, batch_ys = mnist.test.next_batch(30)\n",
    "#Bald Bangs Black_Hair Blond_Hair Eyeglasses Male Pale_Skin Smiling\n",
    "test_y = [[0, 1],\n",
    "          [0, 1],\n",
    "          [1, 0],\n",
    "          [1, 0],\n",
    "          [0, 1],\n",
    "          [0, 1],\n",
    "          [1, 0],\n",
    "          [0, 1]]\n",
    "tail_test = att_all[-24:]\n",
    "test_y.extend(tail_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "data_batch = data[-32:]\n",
    "test_batch = get_imgs(data_batch)\n",
    "test_image = []\n",
    "for i in range(32):\n",
    "    feed_dict={input_img:test_batch,x_attr:np.repeat([test_y[i]],32, axis=0)}\n",
    "    samples_test= sess.run(out_img, feed_dict=feed_dict)\n",
    "    test_image.append(samples_test)\n",
    "test_image = np.array(test_image) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "import matplotlib\n",
    "matplotlib.use('Agg')\n",
    "import matplotlib.pyplot as plt\n",
    "%matplotlib inline"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def merge(images):\n",
    "    h, w = 64,64\n",
    "    img = np.zeros((h * 8, w * 8, 3))\n",
    "    for j in range(8):\n",
    "        for i in range(8):\n",
    "            img[j*h:j*h+h, i*w:i*w+w, :] = images[i,j,:,:,:]\n",
    "    return img"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "\n",
    "#img_org = reshape_image(test_batch,8,1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "img_test = merge(test_image)\n",
    "f,axarr=plt.subplots(1,1,figsize=(6,6),sharey=True)\n",
    "# samples\n",
    "axarr.imshow(img_test,interpolation='none')\n",
    "axarr.set_title('original image')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# # Create the model\n",
    "# x = tf.placeholder(tf.float32, [None, 784])\n",
    "# y_ = tf.placeholder(tf.float32, [None, 10])\n",
    "\n",
    "# hidden  = tf.nn.relu(linear(y_,  1000, scope='c_h1', stddev=0.01))\n",
    "# a1 = tf.nn.relu(linear(hidden,  1000, scope='c_a1', stddev=0.01))\n",
    "# a2 = tf.nn.relu(linear(hidden,  1000, scope='c_a2', stddev=0.01))\n",
    "# a3 = tf.nn.relu(linear(hidden,  1000, scope='c_a3', stddev=0.01))\n",
    "# b1 = tf.nn.relu(linear(hidden,  1000, scope='c_b1', stddev=0.01))\n",
    "# b2 = tf.nn.relu(linear(hidden,  1000, scope='c_b2', stddev=0.01))\n",
    "# b3 = tf.nn.relu(linear(hidden,  1000, scope='c_b3', stddev=0.01))\n",
    "\n",
    "\n",
    "\n",
    "# h1 =linear(x,  1000, scope='c_layer1', stddev=0.01)\n",
    "# h1_c = tf.nn.relu(tf.mul(h1,a1)+b1)\n",
    "# h2 = tf.nn.relu(linear(h1_c, 1000, scope='c_layer2', stddev=0.01))\n",
    "# h2_c = tf.nn.relu(tf.mul(h2,a2)+b2)\n",
    "# h3 = tf.nn.relu(linear(h2_c, 1000, scope='c_layer3', stddev=0.01))\n",
    "# h3_c = tf.nn.relu(tf.mul(h3,a3)+b3)\n",
    "# h4 = linear(h3_c, 784, scope='c_layer4', stddev=0.01)\n",
    "# out_vecter = tf.sigmoid(h4)\n",
    "# out_image = tf.reshape(out_vecter,[-1,28,28])\n",
    "\n",
    "# def recognition_network(images,reuse = False):\n",
    "#     if reuse:\n",
    "#             tf.get_variable_scope().reuse_variables()\n",
    "#     output = tf.nn.relu(linear(images, 1000, scope='r_layer1', stddev=0.01))\n",
    "#     output = tf.nn.softmax(linear(output, 10, scope='r_layer2', stddev=0.01))\n",
    "#     return output\n",
    "# # Define loss and optimizer\n",
    "# y_clf = recognition_network(x)\n",
    "# y_clf_g = recognition_network(out_vecter,reuse =True)\n",
    "\n",
    "# cross_entropy_recog = tf.reduce_mean(tf.nn.softmax_cross_entropy_with_logits(y_clf, y_))\n",
    "# cross_entropy_gen = tf.reduce_mean(tf.nn.softmax_cross_entropy_with_logits(y_clf_g, y_)) \n",
    "# # + \\\n",
    "# # tf.reduce_mean(tf.nn.softmax_cross_entropy_with_logits(y_clf_g, y_))\n",
    "# reconstruction_loss = tf.reduce_mean(tf.squared_difference(out_vecter,x))\n",
    "# loss = reconstruction_loss + 7.2*cross_entropy_gen\n",
    "# #cross_entropy = tf.reduce_mean(tf.nn.softmax_cross_entropy_with_logits(y, y_))\n",
    "# #train_step = tf.train.GradientDescentOptimizer(0.01).minimize(loss)\n",
    "# #t_vars = tf.trainable_variables()\n",
    "# t_vars = tf.trainable_variables()\n",
    "# contr_params = [var for var in t_vars if 'c_' in var.name]\n",
    "# recog_params = [var for var in t_vars if 'r_' in var.name]\n",
    "\n",
    "# optim = tf.train.AdamOptimizer(learning_rate=1e-3). \\\n",
    "#         minimize(loss,var_list=contr_params) \n",
    "# optim_recog = tf.train.AdamOptimizer(learning_rate=1e-3). \\\n",
    "#         minimize(cross_entropy_recog,var_list=recog_params) \n",
    "\n",
    "# session_conf = tf.ConfigProto(gpu_options = tf.GPUOptions(per_process_gpu_memory_fraction=0.7),\n",
    "#                               allow_soft_placement=True,\n",
    "#                               log_device_placement=False)\n",
    "# sess = tf.InteractiveSession(config=session_conf)\n",
    "# # Train\n",
    "# tf.initialize_all_variables().run()\n",
    "# batch_size = 100\n",
    "# #pretrain recognition network\n",
    "# # for step in range(5001):\n",
    "# #     batch_xs, batch_ys = mnist.train.next_batch(batch_size)\n",
    "# #     _ = sess.run(optim_recog,feed_dict={x: batch_xs,y_:batch_ys})\n",
    "# for step in range(3001):\n",
    "#     batch_xs, batch_ys = mnist.train.next_batch(batch_size)\n",
    "#     norm_image = np.random.uniform(0, 1, [batch_size,784]).astype(np.float32)\n",
    "#     if np.random.rand(1)>1:\n",
    "#         batch_xs = norm_image\n",
    "#     x_bat = np.reshape(batch_xs,[-1,28,28])\n",
    "#     samples,_,_,loss_,cross_entropy_gen_,reconstruction_loss_ = sess.run([out_image,\n",
    "#                                                                         optim_recog,\n",
    "#                                                                           optim,\n",
    "#                                                                           loss,\n",
    "#                                                                           cross_entropy_gen,\n",
    "#                                                                           reconstruction_loss]\n",
    "#                                                                           ,feed_dict={x: batch_xs,y_:batch_ys})\n",
    "    \n",
    "#     if step %50 ==0:\n",
    "#         print('step : '+str(step)+' loss : '+ str(loss_)\\\n",
    "#               +' loss_reconstruction : '+ str(reconstruction_loss_)\\\n",
    "#               +' loss_gen : '+ str(cross_entropy_gen_))\n",
    "   \n",
    "#     if step % 2000 ==0:\n",
    "#         scipy.misc.imsave('./sample/%s_input.png'% (step),x_bat[1])    \n",
    "#         scipy.misc.imsave('./sample/%s_output.png'% (step),samples[1])\n",
    "# batch_xs, batch_ys = mnist.test.next_batch(30)\n",
    "# test_y = [[ 1.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.],\n",
    "#           [ 0.,  1.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.],\n",
    "#           [ 0.,  0.,  1.,  0.,  0.,  0.,  0.,  0.,  0.,  0.],\n",
    "#           [ 0.,  0.,  0.,  1.,  0.,  0.,  0.,  0.,  0.,  0.],\n",
    "#           [ 0.,  0.,  0.,  0.,  1.,  0.,  0.,  0.,  0.,  0.],\n",
    "#           [ 0.,  0.,  0.,  0.,  0.,  1.,  0.,  0.,  0.,  0.],\n",
    "#           [ 0.,  0.,  0.,  0.,  0.,  0.,  1.,  0.,  0.,  0.],\n",
    "#           [ 0.,  0.,  0.,  0.,  0.,  0.,  0.,  1.,  0.,  0.],\n",
    "#           [ 0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  1.,  0.],\n",
    "#           [ 0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  1.]]\n",
    "# # feed_dict={x: batch_xs[:len(test_y)],y_:test_y}\n",
    "# # samples_test= sess.run(out_image, feed_dict=feed_dict)\n",
    "# # in_test= np.reshape(batch_xs[0:len(test_y)],[-1,28,28])\n",
    "# # for i in range(len(test_y)):\n",
    "# #     scipy.misc.imsave('./sample/%s_test_output.png'% (i),samples_test[i])\n",
    "# #     scipy.misc.imsave('./sample/%s_test_input.png'% (i),in_test[i])"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 2",
   "language": "python",
   "name": "python2"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
